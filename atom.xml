<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>爆发🍢小宇宙</title>
  
  <subtitle>所有的身不由己，都是因为不够强大</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://zhangzongyu00.github.io/"/>
  <updated>2020-06-10T02:15:16.000Z</updated>
  <id>http://zhangzongyu00.github.io/</id>
  
  <author>
    <name>章肿鱼</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>生成对抗网络</title>
    <link href="http://zhangzongyu00.github.io/2020/06/09/%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/"/>
    <id>http://zhangzongyu00.github.io/2020/06/09/%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/</id>
    <published>2020-06-09T05:05:22.000Z</published>
    <updated>2020-06-10T02:15:16.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考：<br><a href="https://blog.csdn.net/gdymind/article/details/82696481" target="_blank" rel="noopener">https://blog.csdn.net/gdymind/article/details/82696481</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;参考：&lt;br&gt;&lt;a href=&quot;https://blog.csdn.net/gdymind/article/details/82696481&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://blog.csdn.net/gdymind/arti
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>卷积神经网络</title>
    <link href="http://zhangzongyu00.github.io/2020/06/08/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    <id>http://zhangzongyu00.github.io/2020/06/08/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</id>
    <published>2020-06-08T02:39:27.000Z</published>
    <updated>2020-06-09T11:59:15.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="CNN基本组件"><a href="#CNN基本组件" class="headerlink" title="CNN基本组件"></a>CNN基本组件</h1><h2 id="卷积层-Convolutional-layer"><a href="#卷积层-Convolutional-layer" class="headerlink" title="卷积层 Convolutional_layer"></a>卷积层 Convolutional_layer</h2><p>用一个采样器从输入数据中采集关键数据内容；</p><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/CNN%E5%8D%B7%E7%A7%AF%E5%8E%9F%E7%90%86.png" alt="CNN卷积原理"></p><p>3D滤波器/卷积核：</p><ul><li>以扫描窗的方式，对图像做卷积；</li><li><strong>每层包含多个卷积核，每个核对应一个输出通道</strong>；</li><li>用于提取局部特征；</li><li>权重参数根据训练学习获得。</li></ul><p>通过代码看卷积核的超参数：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nn.Conv2d(self, in_channels, out_channels, kernel_size, stride&#x3D;1, padding&#x3D;0, dilation&#x3D;1, groups&#x3D;1, bias&#x3D;True))</span><br></pre></td></tr></table></figure><ul><li>in_channel：输入数据的通道数;</li><li>out_channel：输出数据的通道数，根据模型调整，对应<strong>滤波器/卷积核的数量</strong>；</li><li>kennel_size：卷积核大小；</li><li>Stride：步长，默认为1；</li><li>padding：zero padding。</li></ul><p><em>卷积操作一般要把卷积核旋转$180^\circ$再相乘的(反向传播)。</em></p><a href="/2020/06/05/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/" title="激活函数">激活函数</a><h2 id="池化层-Pooling-layer"><a href="#池化层-Pooling-layer" class="headerlink" title="池化层 Pooling_layer"></a>池化层 Pooling_layer</h2><p>对卷积层结果进行压缩，得到更加重要的特征，并有效控制过拟合。</p><p>计算类别：</p><ul><li>平均池化</li><li>最大池化</li></ul><p>通过代码查看最大池化层的超参数设置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nn.MaxPool2d(kernel_size, stride&#x3D;None, padding&#x3D;0, dilation&#x3D;1, return_indices&#x3D;False, ceil_mode&#x3D;False)</span><br></pre></td></tr></table></figure><ul><li>kernel_size(int or tuple)：max pooling的窗口大小；</li><li>stride(int or tuple, optional)：max pooling的窗口移动的步长，默认kernel_size；</li><li>padding(int or tuple, optional)：输入的每一条边补充0的层数；</li><li>dilation(int or tuple, optional)：一个控制窗口中元素步幅的参数；</li><li>return_indices：若为True，返回输出最大值的序号，对于上采样操作有帮助；</li><li>ceil_mode：若为True，计算输出信号大小时，会使用向上取整，默认向下取整。</li></ul><h3 id="池化层的误差反向传播"><a href="#池化层的误差反向传播" class="headerlink" title="池化层的误差反向传播"></a>池化层的误差反向传播</h3><p>对pooling进行填充后，将卷积核旋转$180^\circ$，进行反向传播计算。</p><ol><li>mean-pooling</li></ol><ul><li>使用等值复制方式，将[[1,2],[3,4]]变为[[1,1,2,2],[1,1,2,2],[3,3,4,4],[3,3,4,4]];</li><li>需要满足反向传播时各层间残差总和不变，所以对卷积层对应的每个值需要平摊。</li></ul><ol start="2"><li>max-pooling</li></ol><ul><li>前向传播过程中<strong>需要记录pooling区域中最大值的位置</strong>；</li><li>将[[1,2],[3,4]]放入对应的最大值位置，如[[1,0,0,2],[0,0,0,0],[0,0,0,0],[3,0,0,4]];</li></ul><h2 id="全连接层-Fully-Connected-layer"><a href="#全连接层-Fully-Connected-layer" class="headerlink" title="全连接层 Fully-Connected_layer"></a>全连接层 Fully-Connected_layer</h2><p>对卷积后高度抽象化的特征进行整合，然后归一化，对各种分类情况输出一个概率，之后的分类器Classifier根据全连接得到的概率进行分类。</p><a href="/2020/06/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" title="SoftMax">SoftMax</a><p>FCL对接n维的software层，得到n类标签的概率，用于构建loss。</p>]]></content>
    
    <summary type="html">
    
      可先简单了解下神经网络
    
    </summary>
    
    
      <category term="deeplearning" scheme="http://zhangzongyu00.github.io/categories/deeplearning/"/>
    
    
      <category term="CNN" scheme="http://zhangzongyu00.github.io/tags/CNN/"/>
    
  </entry>
  
  <entry>
    <title>Adam</title>
    <link href="http://zhangzongyu00.github.io/2020/06/07/Adam/"/>
    <id>http://zhangzongyu00.github.io/2020/06/07/Adam/</id>
    <published>2020-06-07T00:01:39.000Z</published>
    <updated>2020-06-09T05:20:52.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Momentum"><a href="#Momentum" class="headerlink" title="Momentum"></a>Momentum</h1><p>动量momentum借用了物理中的动量概念，即将前几次的梯度也加入计算过程。为了表示动量，引入了一个新的变量v。v是<strong>之前的梯度的累加</strong>，但每回合都有一定的衰减。</p><p>计算梯度估计：<br>$$\widehat{g} \leftarrow + \frac{1}{m} \bigtriangledown_\theta \sum_i L(f(x_i;\theta),y_i)$$<br>计算更新：<br>$$v \leftarrow \alpha v - \epsilon \widehat{g}$$<br>应用更新：<br>$$\theta \leftarrow \theta + v$$</p><p>当前后梯度方向一致时，能够加速学习；前后梯度方向不一致时，能够抑制震荡。</p><h1 id="Nesterov-Momentum"><a href="#Nesterov-Momentum" class="headerlink" title="Nesterov Momentum"></a>Nesterov Momentum</h1><p><em>对momentum的改进</em></p><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/Nesterov_Momentum.png" alt="Nesterov_Momentum"></p><p>计算梯度估计：<br>$$\widehat{g} \leftarrow + \frac{1}{m} \bigtriangledown_\theta \sum_i L(f(x_i;\theta + \alpha v),y_i)$$<br>计算更新：<br>$$v \leftarrow \alpha v - \epsilon \widehat{g}$$<br>应用更新：<br>$$\theta \leftarrow \theta + v$$</p><p>先对参数进行估计，然后使用估计后的参数来计算误差。</p><h1 id="Adagrad"><a href="#Adagrad" class="headerlink" title="Adagrad"></a>Adagrad</h1><p>主要解决：<strong>为不同参数设置不同的学习步长</strong>。</p><p>计算梯度：<br>$$\widehat{g} \leftarrow + \frac{1}{m} \bigtriangledown_\theta \sum_i L(f(x_i;\theta),y_i)$$<br>累积平方梯度：<br>$$r \leftarrow r + \widehat{g} \odot \widehat{g}$$<br>计算更新：<br>$$\bigtriangleup \theta = - \frac{\epsilon}{\delta + \sqrt{r}} \odot \widehat{g}$$<br>应用更新：<br>$$\theta \leftarrow \theta + \bigtriangleup \theta$$</p><p><em>$\delta$为小常数，为了数值稳定，大约设置为$10^{-7}$</em>。</p><p>梯度越小，则学习步长越大；梯度越大，学习步长越小。即缓坡上大步跑，陡坡上小步挪。</p><h1 id="RMSprop"><a href="#RMSprop" class="headerlink" title="RMSprop"></a>RMSprop</h1><p><em>对Adagrad的改进</em></p><p>通过引入一个衰减系数，让r每回合都衰减一定比例。</p><p>计算梯度：<br>$$\widehat{g} \leftarrow + \frac{1}{m} \bigtriangledown_\theta \sum_i L(f(x_i;\theta),y_i)$$<br>累积平方梯度：<br>$$r \leftarrow \rho r + (1 - \rho)\widehat{g} \odot \widehat{g}$$<br>计算更新：<br>$$\bigtriangleup \theta = - \frac{\epsilon}{\delta + \sqrt{r}} \odot \widehat{g}$$<br>应用更新：<br>$$\theta \leftarrow \theta + \bigtriangleup \theta$$</p><p>解决了Adagrad过早结束时间问题，适合处理非平稳目标，对RNN效果好。</p><h1 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h1><p>来源于<code>adaptive moment estimation</code>，自适应矩估计。</p><p>Adam本质上是带有动量项的RMSprop，利用梯度的一阶矩估计和二阶矩估计来动态调整每个参数的学习率。</p><p>计算梯度：<br>$$\widehat{g} \leftarrow + \frac{1}{m} \bigtriangledown_\theta \sum_i L(f(x_i;\theta),y_i)$$<br>一阶矩估计：<br>$$s \leftarrow \rho_1 s + (1 - \rho_1) g$$<br>$$\widehat{s} \leftarrow \frac{s}{1 - \rho_1^t}$$<br>二阶矩估计：<br>$$r \leftarrow \rho_2 r + (1 - \rho_2) g \odot g$$<br>$$\widehat{r} \leftarrow \frac{r}{1 - \rho_2^t}$$<br>计算更新：<br>$$\bigtriangleup \theta = - \epsilon \frac{\widehat{s}}{\sqrt{\widehat{r}} + \delta}$$<br>应用更新：<br>$$\theta \leftarrow \theta + \bigtriangleup \theta$$</p><h1 id="几种梯度下降算法比较"><a href="#几种梯度下降算法比较" class="headerlink" title="几种梯度下降算法比较"></a>几种梯度下降算法比较</h1><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/Adam%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95%E6%AF%94%E8%BE%83.png" alt="Adam梯度下降算法比较"></p><ol><li>在minist上训练多层神经网络；</li><li>在cifar10上训练卷积神经网络。</li></ol><p>参考：<br><a href="https://blog.csdn.net/program_developer/article/details/80756008" target="_blank" rel="noopener">https://blog.csdn.net/program_developer/article/details/80756008</a></p>]]></content>
    
    <summary type="html">
    
      当前最常用的梯度下降算法
    
    </summary>
    
    
      <category term="deeplearning" scheme="http://zhangzongyu00.github.io/categories/deeplearning/"/>
    
    
  </entry>
  
  <entry>
    <title>小波变换</title>
    <link href="http://zhangzongyu00.github.io/2020/06/06/%E5%B0%8F%E6%B3%A2%E5%8F%98%E6%8D%A2/"/>
    <id>http://zhangzongyu00.github.io/2020/06/06/%E5%B0%8F%E6%B3%A2%E5%8F%98%E6%8D%A2/</id>
    <published>2020-06-06T05:56:52.000Z</published>
    <updated>2020-06-06T06:40:27.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="连续小波变换CWT"><a href="#连续小波变换CWT" class="headerlink" title="连续小波变换CWT"></a>连续小波变换CWT</h1><p>将无限长的三角函数基转换为有限长的会衰减的小波基，不仅能获取频率，还可定位到时间。</p><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/%E5%B0%8F%E6%B3%A2%E5%8F%98%E6%8D%A2.png" alt="小波变换"></p><p>思路：</p><ol><li>取一个小波，将其与原始信号的开始一节进行比较；</li><li>计算数值F，F表示小波与所取一节信号的相似程度，计算结果取决于所选小波的形状；</li><li>向右移动小波，重复步骤1和步骤2，直至覆盖整个信号；</li><li>伸展小波，重复步骤1-3，对齐；</li><li>对于所有缩放，重复步骤1-4，进行压缩。</li></ol><h1 id="离散小波变换DWT"><a href="#离散小波变换DWT" class="headerlink" title="离散小波变换DWT"></a>离散小波变换DWT</h1><p>离散小波变换的有效方法是使用滤波器，由Mallat于1988年提出。</p><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/%E5%A4%9A%E5%B1%82%E5%B0%8F%E6%B3%A2%E5%88%86%E8%A7%A3%E5%92%8C%E9%87%8D%E6%9E%84.png" alt="多层小波分解和重构"></p><h2 id="小波分解"><a href="#小波分解" class="headerlink" title="小波分解"></a>小波分解</h2><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/%E7%A6%BB%E6%95%A3%E5%B0%8F%E6%B3%A2%E5%88%86%E8%A7%A3%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt="离散小波分解示意图"></p><p>S表示原始的输入信号，通过两个互补的滤波器组，一个低通滤波器，得到信号的近似值A，另一个高通滤波器，得到该滤波器的细节值D。</p><h2 id="小波重构"><a href="#小波重构" class="headerlink" title="小波重构"></a>小波重构</h2><p>利用小波分解的系数还原出原始信号，也叫逆离散小波变换IDWT/小波合成。</p><h1 id="二维离散小波变换"><a href="#二维离散小波变换" class="headerlink" title="二维离散小波变换"></a>二维离散小波变换</h1><p>将二维信号在不同尺度进行分解，得到原始信号的近似值和细节。</p><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/%E4%BA%8C%E7%BB%B4%E5%B0%8F%E6%B3%A2%E5%88%86%E8%A7%A3%E5%92%8C%E9%87%8D%E6%9E%84.png" alt="二维小波分解和重构"></p><p>分解的结果为**近似分量cA、水平细节分量cH、垂直细节分量cV、对角细节分量cD。</p><h1 id="常见小波函数"><a href="#常见小波函数" class="headerlink" title="常见小波函数"></a>常见小波函数</h1><p>Haar系列，Daubechies系列，Moret系列，Sym系列，Meyer系列，Coif系列</p><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/%E5%B8%B8%E7%94%A8%E5%B0%8F%E6%B3%A2%E5%87%BD%E6%95%B0.png" alt="常用小波函数"></p><p>参考：<br><a href="https://www.cnblogs.com/keye/p/7809207.html" target="_blank" rel="noopener">https://www.cnblogs.com/keye/p/7809207.html</a><br><a href="https://wenku.baidu.com/view/5b1abd048e9951e79b8927de.html" target="_blank" rel="noopener">https://wenku.baidu.com/view/5b1abd048e9951e79b8927de.html</a></p>]]></content>
    
    <summary type="html">
    
      小波变换就是将一个信号分解为一系列小波进行处理的过程。
    
    </summary>
    
    
      <category term="image" scheme="http://zhangzongyu00.github.io/categories/image/"/>
    
    
      <category term="多尺度变换" scheme="http://zhangzongyu00.github.io/tags/%E5%A4%9A%E5%B0%BA%E5%BA%A6%E5%8F%98%E6%8D%A2/"/>
    
  </entry>
  
  <entry>
    <title>VS-Code配置</title>
    <link href="http://zhangzongyu00.github.io/2020/06/06/VSCode%E9%85%8D%E7%BD%AE/"/>
    <id>http://zhangzongyu00.github.io/2020/06/06/VSCode%E9%85%8D%E7%BD%AE/</id>
    <published>2020-06-06T05:41:39.000Z</published>
    <updated>2020-06-09T06:03:27.000Z</updated>
    
    <content type="html"><![CDATA[<p>配置C环境<br><a href="https://www.jianshu.com/p/83879b4aa3fe" target="_blank" rel="noopener">https://www.jianshu.com/p/83879b4aa3fe</a></p><p>Latex学习<br><a href="https://www.cnblogs.com/zyg123/category/1415008.html" target="_blank" rel="noopener">https://www.cnblogs.com/zyg123/category/1415008.html</a></p>]]></content>
    
    <summary type="html">
    
      万能的VS-Code配置
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>直方图均衡化</title>
    <link href="http://zhangzongyu00.github.io/2020/06/06/%E7%9B%B4%E6%96%B9%E5%9B%BE%E5%9D%87%E8%A1%A1%E5%8C%96/"/>
    <id>http://zhangzongyu00.github.io/2020/06/06/%E7%9B%B4%E6%96%B9%E5%9B%BE%E5%9D%87%E8%A1%A1%E5%8C%96/</id>
    <published>2020-06-06T04:28:12.000Z</published>
    <updated>2020-06-09T05:58:10.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="直方图均衡化"><a href="#直方图均衡化" class="headerlink" title="直方图均衡化"></a>直方图均衡化</h1><ul><li>实质上是对图像进行非线性拉伸，重新分配各个灰度单位的像素点数量，使其均匀分布；</li><li>利用图像直方图对图像的对比度进行调整；</li><li>通常用于增强局部的对比度而不影响整体对比度，过黑或过曝的处理。</li></ul><p>思路：</p><ol><li>统计每个颜色出现的概率；</li><li>计算累计概率；</li><li>根据累计概率求取新的颜色映射表：p*255；</li><li>利用新颜色映射表完成颜色映射。</li></ol><h2 id="自适应直方图均衡AHE"><a href="#自适应直方图均衡AHE" class="headerlink" title="自适应直方图均衡AHE"></a>自适应直方图均衡AHE</h2><ul><li>移动模版在源图像上按stride滑动；</li><li>移动后，模版区域内做直方图均衡，映射后的结果赋值给模版区域内所有点；</li><li>对每个点取多次赋值的均值。</li></ul><p>缺点：过度放大平滑区域噪声。</p><h2 id="CLAHE（自适应直方图均衡）"><a href="#CLAHE（自适应直方图均衡）" class="headerlink" title="CLAHE（自适应直方图均衡）"></a>CLAHE（自适应直方图均衡）</h2><p>算法步骤：</p><ol><li>对图像进行分块，以块为单位；</li><li>先计算直方图，然后对其进行修剪，然后均衡；<br><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/CLAHE%E4%BF%AE%E5%89%AA.png" alt="CLAHE修剪"></li><li>遍历各个图像块，对块间区域进行双线性差值，使图像平滑；</li><li>与源图像做涂层滤色混合操作（可选）。</li></ol><p>映射关系：<br>    <img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/CLAHE%E6%98%A0%E5%B0%84.png" alt="CLAHE映射"></p><ul><li>小黑点处的灰度值由映射函数直接计算得出；</li><li>粉色区域灰度值由映射函数计算得出；</li><li>滤色区域灰度值由相邻2块灰度值映射线性插值得出；</li><li>紫色区域灰度值由相邻4块灰度值映射线性插值得出。</li></ul>]]></content>
    
    <summary type="html">
    
      使用直方图对图像的颜色空间进行映射
    
    </summary>
    
    
      <category term="image" scheme="http://zhangzongyu00.github.io/categories/image/"/>
    
    
      <category term="多尺度变换" scheme="http://zhangzongyu00.github.io/tags/%E5%A4%9A%E5%B0%BA%E5%BA%A6%E5%8F%98%E6%8D%A2/"/>
    
  </entry>
  
  <entry>
    <title>kmeans聚类</title>
    <link href="http://zhangzongyu00.github.io/2020/06/06/kmeans%E8%81%9A%E7%B1%BB/"/>
    <id>http://zhangzongyu00.github.io/2020/06/06/kmeans%E8%81%9A%E7%B1%BB/</id>
    <published>2020-06-06T04:22:49.000Z</published>
    <updated>2020-06-09T06:02:48.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="K-means"><a href="#K-means" class="headerlink" title="K-means"></a>K-means</h1><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/K-means.png" alt="K-means"></p><p>算法流程：</p><ol><li>选取k个类中心（首次随机选取）；</li><li>计算每个点到k个类中心的距离；</li><li>将数据点分配给距离最近的一个类中心；</li><li>计算新的类中心（对该类中所有点取均值）；</li><li>重复2-4，直到满足终止条件：<ul><li>不再有重新分配；</li><li>最大迭代数；</li><li>所有类中心移动小于某一个值。</li></ul></li></ol>]]></content>
    
    <summary type="html">
    
      将数据点分配给距离最近的一个类中心，不断修改迭代的过程
    
    </summary>
    
    
      <category term="image" scheme="http://zhangzongyu00.github.io/categories/image/"/>
    
    
  </entry>
  
  <entry>
    <title>GrabCut分割</title>
    <link href="http://zhangzongyu00.github.io/2020/06/06/GrabCut%E5%88%86%E5%89%B2/"/>
    <id>http://zhangzongyu00.github.io/2020/06/06/GrabCut%E5%88%86%E5%89%B2/</id>
    <published>2020-06-06T04:18:23.000Z</published>
    <updated>2020-06-09T05:59:58.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="GrabCut分割"><a href="#GrabCut分割" class="headerlink" title="GrabCut分割"></a>GrabCut分割</h1><p>前景/背景的颜色模型：</p><ul><li>假定前景和背景为高斯混合模型GMM；</li><li>对于每个要素，均来自于目标GMM/背景GMM的某个高斯分量；</li><li>用边界项来表示邻域像素间不连续的惩罚，若两邻域像素差别很小，则属于同一目标/背景的可能性就大，反之可能为边缘；</li><li>通过<a href="/2020/06/06/kmeans%E8%81%9A%E7%B1%BB/" title="kmeans聚类">kmeans聚类</a>算法迭代获得。</li></ul><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/GrabCut.png" alt="GrabCut"></p><p>算法流程：</p><ol><li>使用标记初始化颜色模型（k=5）；</li><li>迭代进行GraphCut；<ul><li>优化前景/背景的颜色模型；</li><li>能量会随着不断迭代变小；</li><li>分割效果也越来越好。</li></ul></li></ol><h2 id="高斯混合模型GMM"><a href="#高斯混合模型GMM" class="headerlink" title="高斯混合模型GMM"></a>高斯混合模型GMM</h2><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/GMM.png" alt="GMM"></p><p>两组点分别通过两个不同的正态分布随机生成。</p>]]></content>
    
    <summary type="html">
    
      使用Kmeans和gmm方法对图像中的像素点进行分割
    
    </summary>
    
    
      <category term="image" scheme="http://zhangzongyu00.github.io/categories/image/"/>
    
    
      <category term="图像分割" scheme="http://zhangzongyu00.github.io/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/"/>
    
  </entry>
  
  <entry>
    <title>GraphCuts分割</title>
    <link href="http://zhangzongyu00.github.io/2020/06/06/GraphCuts%E5%88%86%E5%89%B2/"/>
    <id>http://zhangzongyu00.github.io/2020/06/06/GraphCuts%E5%88%86%E5%89%B2/</id>
    <published>2020-06-06T04:14:21.000Z</published>
    <updated>2020-06-09T06:00:53.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="GraphCuts分割"><a href="#GraphCuts分割" class="headerlink" title="GraphCuts分割"></a>GraphCuts分割</h1><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/GraphCuts.png" alt="GraphCuts"></p><ul><li>普通顶点对应于图像中的每个像素。每两个邻域顶点的连接为一条边。</li><li>两个终端顶点：S(source:前景)、T(sink:背景)。每个普通顶点和这2个终端顶点进行连接，称为第二种边。</li></ul><p>GraphCuts中的Cuts指这样一个边的集合，该集合中的所有边的断开，会导致残留S和T图的分开，被称为割。<br>如果一个割，它的边的所有权值之和最小，就称其为<strong>最小割</strong>，即GraphCuts的结果。</p><p>基于能量的算法：<br>    $E(A) = \lambda \cdot R(A) + B(A)$<br>    $R(A) = \sum_{p \in \mathcal{P}} R_p(A_p)$<br>    $B(A) = \sum_{ {p,q} \in \mathcal{N} } B_{ {p,q} } \cdot \delta(A_p,A_q)$<br>    <img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/GraphCuts%E8%83%BD%E9%87%8F.png" alt="GraphCuts能量"><br><em>区域项R(A)、边界项B(A)</em></p><p>R是为像素p分配标签$I_p$的惩罚：<br>    当像素p的灰度值属于目标的概率大于背景，$R_p(1) &lt; R_p(0)$，即像素p更有可能属于目标时，将p归为目标会使能量R(L)更小。</p><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/%E5%9B%BE%E5%89%B2%E5%89%8D%E8%83%8C%E6%99%AF%E5%88%86%E5%89%B2%E5%85%AC%E5%BC%8F.png" alt="图割前背景分割公式"><br>B是像素p和q之间不连续的惩罚，一般来说，如果p和q越相似，B越大；若非常不同，B趋向于0。</p><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/GraphCuts%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%E8%BF%87%E7%A8%8B.png" alt="GraphCuts基本操作过程"></p><p>基本操作过程：</p><ol><li>先取两个种子点；</li><li>然后建立一个图，图中边的粗细表示对应权值大小；</li><li>找到权值和最小的边的组合；</li><li>完成图像分割。</li></ol>]]></content>
    
    <summary type="html">
    
      对GrabCut的改进
    
    </summary>
    
    
      <category term="image" scheme="http://zhangzongyu00.github.io/categories/image/"/>
    
    
      <category term="图像分割" scheme="http://zhangzongyu00.github.io/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/"/>
    
  </entry>
  
  <entry>
    <title>深度学习</title>
    <link href="http://zhangzongyu00.github.io/2020/06/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    <id>http://zhangzongyu00.github.io/2020/06/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</id>
    <published>2020-06-05T17:53:24.000Z</published>
    <updated>2020-06-09T05:31:31.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="深度学习与神经网络的区别"><a href="#深度学习与神经网络的区别" class="headerlink" title="深度学习与神经网络的区别"></a>深度学习与神经网络的区别</h1><ul><li>网络架构：3-5层$\longrightarrow$上千层</li><li>激活函数：sigmoid$\longrightarrow$ReLU</li><li>层间连接：全连接$\longrightarrow$权值共享、ResNet</li><li>梯度下降：SGD$\longrightarrow$Adam<br>   一般先用Adam快速验证，再精调SGD进行极致优化。</li><li>目标函数：MSE$\longrightarrow$CE</li><li>除过拟合：凭经验$\longrightarrow$Dropout</li></ul><h1 id="SoftMax"><a href="#SoftMax" class="headerlink" title="SoftMax"></a>SoftMax</h1><p>SoftMax层的作用是突出最大值，并转换成概率的形式。</p><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/softMax.jpg" alt="softMax"></p><p>将一些输入映射为0-1之间的实数，并且归一化保证和为1，并且按照概率分布，即分值大的值取到的概率大，分值小的值偶尔取到。</p><p>假定现有一个数组V，v_i 表示V中第i个元素，那么这个元素的soft-max值为$s_i = \frac{e^i}{\sum_j e^j}$</p><h1 id="梯度消失问题"><a href="#梯度消失问题" class="headerlink" title="梯度消失问题"></a>梯度消失问题</h1><p>随着网络层数的增加，网络发生了退化(degradation)的现象：</p><ul><li>随着网络层数的增多，训练集loss逐渐下降，然后趋于饱和；</li><li>当再增加网络深度时，训练集loss反而会增大；</li><li>不是过拟合，因为在过拟合中训练loss是一直减小的。</li></ul><p>梯度消失的原因：</p><ul><li>神经元的激活函数采用了Sigmoid函数；</li><li>大部分情况下$|w| &lt; 1$，而Sigmoid的导数$\sigma’ &lt; \frac{1}{4}$。</li></ul><p>2006年，Hinton等用受限玻尔兹曼机RBM预训练的方式解决梯度消失的问题；<br>2015年，开始使用<a href="/2020/06/05/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/" title="ReLU">ReLU</a>激活函数。</p><h1 id="目标函数-损失函数-代价函数"><a href="#目标函数-损失函数-代价函数" class="headerlink" title="目标函数/损失函数/代价函数"></a>目标函数/损失函数/代价函数</h1><h2 id="均方误差"><a href="#均方误差" class="headerlink" title="均方误差"></a>均方误差</h2><p>$$\sum_{i=1}^n (y_i - \widehat{y}_i)^2$$</p><p>预测得到的结果与真实值间的误差的平方和的平均值。</p><h2 id="交叉熵"><a href="#交叉熵" class="headerlink" title="交叉熵"></a>交叉熵</h2><p>$$-\sum_{i=1}^n \widehat{y}_i ln y_i = 0$$</p><p>计算出的y值不可能为0，可避免计算困难。<br>交叉熵目标函数的最优值搜索空间的“地形”更陡，更有利于快速找到最优值。</p><h1 id="学习步长"><a href="#学习步长" class="headerlink" title="学习步长"></a>学习步长</h1><ul><li>若学习步长过大，则目标函数可能不降低；</li><li>若学习步长过小，训练过程可能非常缓慢。</li></ul><p>解决方法：训练几轮后按一些因素调整学习步长。</p><h1 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h1><p>对于每个隐层神经元，把逐渐向非线性函数映射后向取值区间极限饱和区靠拢的输入分布强制拉回到均值为0方差为1的比较标准的正态分布，使得非线性变换函数的输入值落入对输入比较敏感的区域，以此避免梯度消失问题。</p><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/Batch_Normalization.png" alt="Batch_Normalization"></p><ul><li>在每次SGD时，通过mini-batch来对相应的activation做规范化操作，使得输出信号各维度的均值为0，方差为1；</li><li>最后的<code>scale and shift</code>是为了让因训练所需而刻意加入的BN能够还原最初的输入。</li></ul><h1 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h1><p>当目标函数在<code>验证集</code>上不再减小时，训练就应该停止了，不能一味追求<code>训练集</code>的误差减小。</p><p>权重衰减：因为在BP中很多权重是无用的，因此对于原梯度下降$w \leftarrow w - \eta \frac{\partial L}{\partial w}$将权重衰减为$w \leftarrow (1-\lambda)w - \eta \frac{\partial L}{\partial w}$，其中，$\lambda$为衰减率，随着训练持续越来越小。</p><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/Dropout.jpg" alt="Dropout"></p><ul><li>每次更新参数前，按照一定的比例来删减部分神经元；</li><li>Dropout是集成学习的一种，使用一小块数据来训练一系列“子网络”。</li></ul><p><strong>测试时，要使用所有神经元，并且权重要按照同衰减比例缩小。</strong></p><p>参考：<br><a href="https://www.cnblogs.com/guoyaohua/p/8724433.html" target="_blank" rel="noopener">https://www.cnblogs.com/guoyaohua/p/8724433.html</a></p>]]></content>
    
    <summary type="html">
    
      简述深度学习中的常用到的一些基本概念
    
    </summary>
    
    
      <category term="deeplearning" scheme="http://zhangzongyu00.github.io/categories/deeplearning/"/>
    
    
  </entry>
  
  <entry>
    <title>监督学习</title>
    <link href="http://zhangzongyu00.github.io/2020/06/05/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
    <id>http://zhangzongyu00.github.io/2020/06/05/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/</id>
    <published>2020-06-05T07:16:32.000Z</published>
    <updated>2020-06-09T05:32:19.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Delta学习规则"><a href="#Delta学习规则" class="headerlink" title="Delta学习规则"></a>Delta学习规则</h1><p>通过神经元的实际输出，与期望输出的差别，来调整连接权重。</p><p>$$\bigtriangleup w_{ij} = a \cdot (d_i - y_i) x_j(t)$$</p><p>其中,</p><ul><li>$\bigtriangleup w_{ij}$表示神经元j到神经元i的连接权重增量；</li><li>$d_i$是神经元i的期望输出；</li><li>$y_i$是神经元i的实际输出；</li><li>$x_i$是神经元j的状态；</li><li>$a$表示学习速率。</li></ul>]]></content>
    
    <summary type="html">
    
      通过输入与输出的差别来调整目标权重
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>图像格式</title>
    <link href="http://zhangzongyu00.github.io/2020/06/05/%E5%9B%BE%E5%83%8F%E6%A0%BC%E5%BC%8F/"/>
    <id>http://zhangzongyu00.github.io/2020/06/05/%E5%9B%BE%E5%83%8F%E6%A0%BC%E5%BC%8F/</id>
    <published>2020-06-05T06:53:38.000Z</published>
    <updated>2020-06-09T05:55:50.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="图片存储格式"><a href="#图片存储格式" class="headerlink" title="图片存储格式"></a>图片存储格式</h1><p>常用存储格式：<br>  bmp,jpg,png,tiff,gif,<br>  pcx,tga,exif,fpx,svg,<br>  psd,cdr,pcd,dxf,ufo,<br>  eps,ai,raw,WMF,webp等。</p><ul><li>BMP：采用位映射存储，占用空间大。</li><li>JPG：常用有损压缩格式，压缩比例可达10:1-40:1。</li><li>PNG：无损压缩图像文件格式，比GIF小30%。</li><li>GIF：基于LZW算法的连续色调的无损压缩格式，压缩率一般在50%左右。</li></ul>]]></content>
    
    <summary type="html">
    
      图像的存储格式问题
    
    </summary>
    
    
      <category term="image" scheme="http://zhangzongyu00.github.io/categories/image/"/>
    
    
  </entry>
  
  <entry>
    <title>激活函数</title>
    <link href="http://zhangzongyu00.github.io/2020/06/05/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"/>
    <id>http://zhangzongyu00.github.io/2020/06/05/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/</id>
    <published>2020-06-04T17:42:44.000Z</published>
    <updated>2020-06-09T05:34:29.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="sigmoid"><a href="#sigmoid" class="headerlink" title="sigmoid"></a>sigmoid</h1><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/sigmoid.jpg" alt="sigmoid"></p><p>$g(z) = \frac{1}{1 + e^{-z}}$</p><p>常用于二元分类的输出层，输出介于0-1之间。</p><h1 id="tanh"><a href="#tanh" class="headerlink" title="tanh"></a>tanh</h1><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/tanh.png" alt="tanh"></p><p>$tanh(x) = \frac{e^x - e^{-x}}{e^{-x} + e^x}$</p><h1 id="ReLu"><a href="#ReLu" class="headerlink" title="ReLu"></a>ReLu</h1><p><em>rectified linear unit，修正线性单元</em></p><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/ReLU.jpg" alt="ReLU"></p><ul><li>常规ReLU：$Max(0,x_i)$<ul><li>当$x\geq0$时，$y_i=x_i$；</li><li>当$x&lt;0$时，$y_i=0$；</li></ul></li><li>Leaky ReLU：$Max(ax_i,x_i)$<ul><li>当$x\geq0$时，$y_i=x_i$；</li><li>当$x&lt;0$时，$y_i=a_i x_i$；</li></ul></li><li>Randomized Leaky ReLU：<ul><li>当$x\geq0$时，$y_i=x_i$；</li><li>当$x&lt;0$时，$y_{ji}=a_{ji} x_{ji}$；</li></ul></li></ul><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/ReLU%E6%BF%80%E6%B4%BB.png" alt="ReLU激活"></p><p>使用ReLU激活后，一些单元的输出成了0，另一些则变为线性单元，避免了调整各层权重时的梯度消失的问题。</p><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/ReLU%E4%BC%98%E5%8C%96.png" alt="ReLU优化"></p>]]></content>
    
    <summary type="html">
    
      用于拟合数据间的关系
    
    </summary>
    
    
      <category term="deeplearning" scheme="http://zhangzongyu00.github.io/categories/deeplearning/"/>
    
    
  </entry>
  
  <entry>
    <title>神经网络</title>
    <link href="http://zhangzongyu00.github.io/2020/06/05/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    <id>http://zhangzongyu00.github.io/2020/06/05/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</id>
    <published>2020-06-04T17:22:26.000Z</published>
    <updated>2020-06-09T05:16:58.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h1><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.png" alt="人工神经网络"></p><p>神经网络：由大量神经元节点按照一定体系架构连接而成的网状结构，一般包含输入层、隐藏层、输出层三部分。</p><p>神经网络可用于分类、模式识别、连续值预测 etc. </p><p><em>一般的浅层网络只有3-5层，这也是区别于DL的主要地方。</em></p><h2 id="神经元"><a href="#神经元" class="headerlink" title="神经元"></a>神经元</h2><h3 id="生物神经元"><a href="#生物神经元" class="headerlink" title="生物神经元"></a>生物神经元</h3><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/%E7%94%9F%E7%89%A9%E7%A5%9E%E7%BB%8F%E5%85%83.jpg" alt="生物神经元"></p><p>生物神经元之间的相互连接，使得信息在大脑中得以传递。</p><h3 id="人工神经元"><a href="#人工神经元" class="headerlink" title="人工神经元"></a>人工神经元</h3><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E5%85%83.jpg" alt="人工神经元"></p><p>每个神经元都是一个结构相似的独立单元，接受前一层传来的数据，并将其加权和输入到非线性激活函数中，然后，将非线性激活函数的输出传递给下一层。</p><p>神经元包括以下内容：</p><ul><li>输入向量x；</li><li>权重向量w；</li><li>偏置向量b；</li><li>激活函数f；</li></ul><h2 id="前馈神经网络"><a href="#前馈神经网络" class="headerlink" title="前馈神经网络"></a>前馈神经网络</h2><ul><li>前馈神经网络采用一种单向多层结构；</li><li>各神经元从输入层开始，接收前一级输入，并输出到下一级，直到输出层。</li><li>每一层包含若干各神经元，同一层间的神经元间没有连接，层间信息的传递只沿一个方向进行；</li><li>整个网络中没有反馈，类似一个有向无环图。</li></ul><h3 id="目标函数"><a href="#目标函数" class="headerlink" title="目标函数"></a>目标函数</h3><a href="/2020/06/05/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" title="Delta学习规则">Delta学习规则</a><p>$$J(w) = \frac{1}{2} \Vert t - z \Vert^2 = \frac{1}{2} \sum_{k=1}^c (t_k - z_k)^2$$<br>其中，$t = (t_1,…,t_c$表示期望输出，$z = (z_1,…,z_c$表示实际输出。</p><h2 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h2><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/gradient_descent.png" alt="gradient_descent"></p><p>这是一个表示参数w与目标函数J(w)的关系图，红色部分表示J(w)有较高取值，需要让J(w)的值尽可能降低，到达深蓝色部分。</p><p>$$w(m+1) = w(m) + \bigtriangleup w(m) = w(m) - \eta \frac{\partial J}{\partial w}$$</p><p>看到一个很形象的示意图：<br><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt="梯度下降示意图"></p><p>整体思路：</p><ul><li>先确定一个初始点；</li><li>将w按照梯度下降方向进行调整，使J(w)向更低方向变化；</li><li>直到，w无法继续下降为止。</li></ul><h2 id="误差反向传播"><a href="#误差反向传播" class="headerlink" title="误差反向传播"></a>误差反向传播</h2><p>定义几个变量：J为目标函数；z为输出结果；$net_k$为输出单元的总输入；$net_j$为隐藏层单元的总输入；$y_j$为隐藏层单元的输出。</p><ol><li>输出层权重改变量：</li></ol><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/%E8%BE%93%E5%87%BA%E5%B1%82%E6%9D%83%E9%87%8D%E6%94%B9%E5%8F%98.png" alt="输出层权重改变"></p><p>$$\frac{\partial J}{\partial w_{kj}} = \frac{\partial J}{\partial net_k} \frac{\partial net_k}{\partial w_{kj}}$$</p><p>其中，</p><ul><li>$$J(w) = \frac{1}{2} \Vert t - z \Vert^2 = \frac{1}{2} \sum_{k=1}^c (t_k - z_k)^2$$</li><li>$$net_k = \sum_{i=1}^{n_H} w_{ki}y_i$$</li><li>$$\frac{\partial J}{\partial net_k} = \frac{\partial J}{\partial z_k} \frac{\partial z_k}{\partial net_k} = -(t_k - z_k) f’(net_k)$$</li><li>$$\frac{\partial net_k}{\partial w_{kj}} = y_j$$</li></ul><ol start="2"><li>隐藏层权重改变量：</li></ol><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/%E9%9A%90%E8%97%8F%E5%B1%82%E6%9D%83%E9%87%8D%E6%94%B9%E5%8F%98.png" alt="隐藏层权重改变"></p><ul><li>先找到$w_{ji}$与$net_j$的关系；</li><li>然后找$net_j$与隐藏层输出$y_j$的关系。</li></ul><p>$$\frac{\partial J}{\partial w_{ji}} = \frac{\partial J}{\partial y_j} \frac{\partial y_i}{\partial net_j} \frac{\partial net_j}{\partial w_{ji}}$$</p><p>其中，</p><ul><li>$$\frac{\partial net_j}{\partial w_{ji}} = \frac{\partial}{\partial w_{ji}} (\sum_{m=1}^d w_{jm} x_m) = x_i$$</li><li>$$\frac{\partial y_j}{\partial net_j} = f’(net_j)$$</li><li>$$\frac{\partial J}{\partial y_i} = \frac{\partial}{\partial y_j} [\frac{1}{2} \sum_{k=1}^{c} (t_k - z_k)^2] = -\sum_{k=1}^c (t_k - z_k) \frac{\partial z_k}{\partial y_i} = -\sum_{k=1}^c (t_k - z_k) \frac{\partial z_k}{\partial net_k} \frac{\partial net_k}{\partial y_i} =  -\sum_{k=1}^c (t_k - z_k) f’(net_k) w_{kj}$$</li></ul><ol start="3"><li>输出层和隐藏层的误差传播公式可统一为：</li></ol><ul><li>权重增量 = -1 * 学习步长 * 目标函数对权重的偏导数；</li><li>目标函数对权重的偏导数 = -1 * 残差 * 当前层的输入；</li><li>残差 = 当前层激活函数的导数 * 上层反传的误差；</li><li>上层反传的误差 = 上层残差的加权和。</li></ul><h3 id="Stochastic-Gradient-Descent"><a href="#Stochastic-Gradient-Descent" class="headerlink" title="Stochastic Gradient Descent"></a>Stochastic Gradient Descent</h3><p>随机梯度下降SGD在样本量很大时，对每个样本迭代更新速度过慢，可能只需其中部分样本即可迭代到最优解。</p><p>SGD噪音比BGD(批量梯度下降)多，因此，并不是每次迭代都向着整体最优方向。</p><p>优点：<strong>稳定</strong>。</p><p>存在的问题：</p><ul><li>学习步长不易确定，太小收敛满，太大损失函数会在极小值处震荡或偏离；</li><li>每个参数的learning rate都相同，当数据稀疏时，难以对出现频率低的特征进行大一点的更新；</li><li>学习过程中容易陷入到马鞍面中，所有方向梯度值几乎为0；</li></ul><p><em>马鞍面：</em></p><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/%E9%A9%AC%E9%9E%8D%E9%9D%A2.png" alt="马鞍面"></p><h3 id="Mini-batch-Gradient-Descent"><a href="#Mini-batch-Gradient-Descent" class="headerlink" title="Mini-batch Gradient Descent"></a>Mini-batch Gradient Descent</h3><p>每次从所有训练数据中取一个子集用于计算梯度，是BGD和SGD的折中。</p><ul><li>在CNN训练时，绝大多数都采用基于mini-batch的随机梯度下降算法为基础进行训练；</li><li>随着输入数据的不断变化，网络中的参数不断调整，网络各层输入数据的分布也不断变化；</li><li>各层在训练的过程中需要不断的改变，以适应新的数据分布，容易造成网络训练困难，难以拟合的问题。</li></ul>]]></content>
    
    <summary type="html">
    
      大量结构简单、功能接近的神经元结点，按照一定的体系架构，连接而成的网状结构，类似于人脑。
    
    </summary>
    
    
      <category term="神经网络" scheme="http://zhangzongyu00.github.io/categories/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
    
  </entry>
  
  <entry>
    <title>贪心算法</title>
    <link href="http://zhangzongyu00.github.io/2020/06/04/%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95/"/>
    <id>http://zhangzongyu00.github.io/2020/06/04/%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95/</id>
    <published>2020-06-03T16:37:07.000Z</published>
    <updated>2020-06-09T05:54:58.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="贪心算法-贪婪算法"><a href="#贪心算法-贪婪算法" class="headerlink" title="贪心算法/贪婪算法"></a>贪心算法/贪婪算法</h1><p>贪心算法，在每一个选择过程中都选择<strong>当前最优解</strong>，从而希望最终结果达到最优的算法。</p><h2 id="算法实现步骤："><a href="#算法实现步骤：" class="headerlink" title="算法实现步骤："></a>算法实现步骤：</h2><ol><li>创建数学模型来描述问题；</li><li>把求解的问题<strong>分成若干个子问题</strong>；</li><li>对每一子问题求解，得到子问题的<strong>局部最优解</strong>；</li><li>把子问题的解局部最优解合成所求问题的一个解。</li></ol><p><strong>贪心算法的实现，要根据具体问题具体分析。</strong></p><h2 id="常用解决的问题："><a href="#常用解决的问题：" class="headerlink" title="常用解决的问题："></a>常用解决的问题：</h2><ul><li>贪心算法可以解决一些最优化问题，如：求图中的最小生成树、求哈夫曼编码、旅行推销员问题等。</li><li>对于其它问题，贪心算法一般不能得到我们所要求的答案，常用作辅助算法或直接解决一些要求结果不是特别严格的问题。</li><li>一旦一个问题可以通过贪心算法来解决，那么贪心算法一般是解决该问题的最好方法。</li></ul><h2 id="优点："><a href="#优点：" class="headerlink" title="优点："></a>优点：</h2><ul><li>对解决问题具有高效性；</li><li>所得结果更接近于最优结果。</li></ul><h2 id="贪心算法与动态规划的不同"><a href="#贪心算法与动态规划的不同" class="headerlink" title="贪心算法与动态规划的不同"></a>贪心算法与动态规划的不同</h2><ul><li>贪心算法要求对每个子问题的解决方案都要做出选择，且不能回退；</li><li>动态规划会保存之前的运算结果，并依据以前的结果对当前方案进行选择，可回退。</li></ul><p>换个思路，就是贪心算法有一个优先级的问题；动态规划则是使用一个数组来进行记录当前方案，会对每一种方法进行尝试。</p>]]></content>
    
    <summary type="html">
    
      对每一子问题求解，得到子问题的局部最优解
    
    </summary>
    
    
      <category term="算法与数据结构" scheme="http://zhangzongyu00.github.io/categories/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
  </entry>
  
  <entry>
    <title>brief特征</title>
    <link href="http://zhangzongyu00.github.io/2020/06/04/brief%E7%89%B9%E5%BE%81/"/>
    <id>http://zhangzongyu00.github.io/2020/06/04/brief%E7%89%B9%E5%BE%81/</id>
    <published>2020-06-03T16:28:14.000Z</published>
    <updated>2020-06-03T17:12:15.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="BRIEF"><a href="#BRIEF" class="headerlink" title="BRIEF"></a>BRIEF</h1><ol><li>平滑图像；</li><li>在特征点周围选择一个Patch，在这个Patch内通过一定方法挑选$n_d$个点对；</li><li>比较点对中两个像素的大小，并进行赋值：<br><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/BRIEF%E8%B5%8B%E5%80%BC.png" alt="BRIEF赋值"></li><li>对所有$n_d$个点对，进行比较，生成一个长$n_d$的二进制串。</li></ol><h2 id="点对的生成方式："><a href="#点对的生成方式：" class="headerlink" title="点对的生成方式："></a>点对的生成方式：</h2><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/%E7%82%B9%E5%AF%B9%E7%94%9F%E6%88%90.png" alt="点对生成"></p><ul><li>X和Y都服从在[-S/2,S/2]范围内的均匀分布，且相互独立；</li><li>X和Y都服从均值为0，方差为$\frac{S^2}{25}$的高斯分布，且相互独立。</li></ul><p><strong>点对的位置一旦随机选定，就不再更改。</strong></p><hr><h1 id="ORB特征描述"><a href="#ORB特征描述" class="headerlink" title="ORB特征描述"></a>ORB特征描述</h1><p>基于Fast角点的特征点检测和BRIEF特征描述技术。</p><ul><li><p>Fast角点检测缺点：</p><ul><li>缺乏尺度不变性；</li><li>通过构建高斯金字塔，在每一层金字塔图像上检测角点，来实现尺度不变性。</li></ul></li><li><p>BRIEF缺点：</p><ul><li>缺乏旋转不变性；</li><li>给Brief添加旋转不变性。</li></ul></li></ul><h2 id="ORB对BRIEF的改进"><a href="#ORB对BRIEF的改进" class="headerlink" title="ORB对BRIEF的改进"></a>ORB对BRIEF的改进</h2><ul><li><p>在计算描述子时建立的坐标系，以关键点为圆心，以关键点和取点区域的形心(圆心)的连线为X轴建立坐标系；</p></li><li><p>计算形心时，圆形区域上每个点的质量是其对应的像素值。</p></li></ul>]]></content>
    
    <summary type="html">
    
      brief特征点对及其ORB改进
    
    </summary>
    
    
      <category term="image" scheme="http://zhangzongyu00.github.io/categories/image/"/>
    
    
      <category term="feature" scheme="http://zhangzongyu00.github.io/tags/feature/"/>
    
  </entry>
  
  <entry>
    <title>hog特征</title>
    <link href="http://zhangzongyu00.github.io/2020/06/04/hog%E7%89%B9%E5%BE%81/"/>
    <id>http://zhangzongyu00.github.io/2020/06/04/hog%E7%89%B9%E5%BE%81/</id>
    <published>2020-06-03T16:18:49.000Z</published>
    <updated>2020-06-09T06:01:45.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="HOG特征"><a href="#HOG特征" class="headerlink" title="HOG特征"></a>HOG特征</h1><ul><li><p>梯度计算</p><ul><li>分别计算水平、垂直梯度（将二维卷积转换为两个一维卷积）的幅值、方向；</li><li>对于彩色图，选取梯度幅值最大的通道。</li></ul></li><li><p>Block拆分</p><ul><li><p>16*16的Block，步长为8，50%的重合；</p><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/block.png" alt="block"></p></li><li><p>包含2*2个Cell；</p><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/cell.png" alt="cell"></p></li><li><p>每个Cell为8*8大小。</p></li></ul></li><li><p>计算每个Cell的梯度方向直方图</p><ul><li><p>9个方向bin(0-180)；</p><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/bin.png" alt="bin"></p></li><li><p>积累梯度幅值；<br>  <em>易受前景/背景对比度及局部光照影响</em>，需对局部细胞单元进行对比度归一化处理：将各Cell组合成大的、空间上连通的区间block，再进行归一化。</p><p>  <img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/hog%E5%BD%92%E4%B8%80%E5%8C%96%E5%A4%84%E7%90%86.png" alt="hog归一化处理"></p></li><li><p>使用位置高斯加权；</p><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/%E4%BD%8D%E7%BD%AE%E9%AB%98%E6%96%AF%E5%8A%A0%E6%9D%83.png" alt="位置高斯加权"></p></li><li><p>相邻bin使用线性插值。</p></li></ul></li><li><p>串联所有Block直方图</p></li></ul><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/%E4%B8%B2%E8%81%94Block.png" alt="串联Block"></p><ul><li>64*128大小图片；</li><li>7*15=105个Block；</li><li>105<em>(2</em>2)*9=3780维。</li></ul><h1 id="实现步骤"><a href="#实现步骤" class="headerlink" title="实现步骤"></a>实现步骤</h1><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/HOG%E6%AD%A5%E9%AA%A4.png" alt="HOG步骤"></p><ol><li>将整个图像进行Gamma空间、颜色归一化；</li><li>计算图像梯度；</li><li>构建方向的直方图；</li><li>将细胞单元组成大的区间；</li><li>收集HOG特征。</li></ol><p><em>行人HOG特征：</em></p><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/%E8%A1%8C%E4%BA%BAHOG%E7%89%B9%E5%BE%81.png" alt="行人HOG特征"></p>]]></content>
    
    <summary type="html">
    
      hog特征，常用于行人检测
    
    </summary>
    
    
      <category term="image" scheme="http://zhangzongyu00.github.io/categories/image/"/>
    
    
      <category term="feature" scheme="http://zhangzongyu00.github.io/tags/feature/"/>
    
  </entry>
  
  <entry>
    <title>级联分类器</title>
    <link href="http://zhangzongyu00.github.io/2020/06/04/%E7%BA%A7%E8%81%94%E5%88%86%E7%B1%BB%E5%99%A8/"/>
    <id>http://zhangzongyu00.github.io/2020/06/04/%E7%BA%A7%E8%81%94%E5%88%86%E7%B1%BB%E5%99%A8/</id>
    <published>2020-06-03T16:13:13.000Z</published>
    <updated>2020-06-09T05:40:34.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="级联分类器"><a href="#级联分类器" class="headerlink" title="级联分类器"></a>级联分类器</h1><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/%E7%BA%A7%E8%81%94%E5%88%86%E7%B1%BB.png" alt="级联分类"></p><p>级联分类器是将多个强分类器连接在一起进行操作，每一个强分类器都由若干个弱分类器加权构成。</p><p>级联分类器，每一个强分类器都是对负样本更敏感，使得每次被强分类器拒绝的，都几乎是负样本。<br>因此，通过所有强分类器的，基本上可以认定为正样本。</p><h1 id="强-弱分类器"><a href="#强-弱分类器" class="headerlink" title="强/弱分类器"></a>强/弱分类器</h1><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/Boosting%E5%88%86%E7%B1%BB%E5%99%A8%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt="Boosting分类器示意图"></p><p>将每轮得到的最佳弱分类器按照一定方法(Boosting)提升为强分类器。</p><h2 id="弱分类器："><a href="#弱分类器：" class="headerlink" title="弱分类器："></a>弱分类器：</h2><p>训练一个弱分类器，即在当前权重分布下，确定f的最优阈值，使该弱分类器对所有训练样本的分类误差最低。</p><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/%E5%BC%B1%E5%88%86%E7%B1%BB%E5%99%A8%E8%AF%86%E5%88%AB%E4%BA%BA%E8%84%B8.png" alt="弱分类器识别人脸"></p><ul><li>在海量特征中，选取一个特征，能够区分是否为人脸，使错误率最低；</li><li>能够以<strong>稍低于50%的错误率</strong>来区分人脸和非人脸图像；</li></ul><hr><h1 id="Adaboost分类器"><a href="#Adaboost分类器" class="headerlink" title="Adaboost分类器"></a>Adaboost分类器</h1><p><em>Adaboost是一种基于级联分类模型的分类器。</em></p><p>adaboost训练：</p><ol><li>初始化数据权值分布；</li><li>遍历阈值p：选取最小阈值p——t；</li><li>计算权重；</li><li>更新训练数据权重分布。</li></ol><p>训练终止条件：</p><ol><li>for循环次数；</li><li>p小于设定阈值。</li></ol>]]></content>
    
    <summary type="html">
    
      由若干个弱分类器加权构成强分类器，将多个强分类器连接进行分类
    
    </summary>
    
    
      <category term="image" scheme="http://zhangzongyu00.github.io/categories/image/"/>
    
    
      <category term="分类器" scheme="http://zhangzongyu00.github.io/tags/%E5%88%86%E7%B1%BB%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>haar特征</title>
    <link href="http://zhangzongyu00.github.io/2020/06/04/haar%E7%89%B9%E5%BE%81/"/>
    <id>http://zhangzongyu00.github.io/2020/06/04/haar%E7%89%B9%E5%BE%81/</id>
    <published>2020-06-03T16:09:49.000Z</published>
    <updated>2020-06-09T06:01:17.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Haar-like特征"><a href="#Haar-like特征" class="headerlink" title="Haar-like特征"></a>Haar-like特征</h1><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/Haar%E7%89%B9%E5%BE%81.png" alt="Haar特征"></p><p>Haar-like模版可以表示出人脸的某些特征，如中间图表示眼睛区域的颜色比脸颊区域的颜色要深；<br>右图表示鼻梁两侧比鼻梁的颜色要深。</p><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/haar-like%E4%BA%BA%E8%84%B8.png" alt="haar-like人脸"></p><h1 id="特征模版"><a href="#特征模版" class="headerlink" title="特征模版"></a>特征模版</h1><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/haar-like.png" alt="haar-like"></p><p>Haar-like特征模版：</p><ul><li>边缘特征；</li><li>线性特征；</li><li>中心特征；</li><li>对角线特征。</li></ul><p>该模版的特征值为：白色矩形像素和 - 黑色矩形像素和。</p><p>特征数量：要考虑模版、位置、缩放 etc.</p><h2 id="快速计算-积分图"><a href="#快速计算-积分图" class="headerlink" title="快速计算-积分图"></a>快速计算-积分图</h2><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/%E7%A7%AF%E5%88%86%E5%9B%BE.png" alt="积分图"></p><p>根据四个角点计算区域内像素和：$A_{ABCD} = A_C - (A_B + A_D - A_A)$。</p>]]></content>
    
    <summary type="html">
    
      haar特征，常用于人脸识别
    
    </summary>
    
    
      <category term="image" scheme="http://zhangzongyu00.github.io/categories/image/"/>
    
    
      <category term="feature" scheme="http://zhangzongyu00.github.io/tags/feature/"/>
    
  </entry>
  
  <entry>
    <title>局部二值LBP</title>
    <link href="http://zhangzongyu00.github.io/2020/06/04/%E5%B1%80%E9%83%A8%E4%BA%8C%E5%80%BCLBP/"/>
    <id>http://zhangzongyu00.github.io/2020/06/04/%E5%B1%80%E9%83%A8%E4%BA%8C%E5%80%BCLBP/</id>
    <published>2020-06-03T16:02:44.000Z</published>
    <updated>2020-06-09T05:43:13.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="LBP-局部二值模式"><a href="#LBP-局部二值模式" class="headerlink" title="LBP-局部二值模式"></a>LBP-局部二值模式</h1><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/lbp.png" alt="lbp"></p><ol><li>将每个像素点与周围点大小比较：<ul><li>半径为R的圆，均匀采样P个点；</li><li>大小量化为0或1.</li></ul></li><li>多个bit组成一个书，统计每个数的直方图。</li></ol><p>解决旋转不变性：</p><ul><li>将LBP周围的二进制码按位旋转，取二进制码最小的值为最终LBP值。</li></ul><h1 id="Extended-LBP-Circular-LBP"><a href="#Extended-LBP-Circular-LBP" class="headerlink" title="Extended LBP/Circular LBP"></a>Extended LBP/Circular LBP</h1><p><img data-src="https://cdn.jsdelivr.net/gh/zhangzongyu00/images/ExtendedLBP.png" alt="ExtendedLBP"></p><p>将3*3邻域扩展到任意领域，并用圆形领域代替正方形领域。</p>]]></content>
    
    <summary type="html">
    
      特征提取方法，对锚点周围像素点进行比较，大的为1，小的为0
    
    </summary>
    
    
      <category term="image" scheme="http://zhangzongyu00.github.io/categories/image/"/>
    
    
      <category term="feature" scheme="http://zhangzongyu00.github.io/tags/feature/"/>
    
  </entry>
  
</feed>
